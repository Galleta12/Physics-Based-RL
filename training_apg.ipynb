{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import functools\n",
    "from IPython.display import HTML\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Sequence, Tuple, Union\n",
    "from brax import base\n",
    "from brax import envs\n",
    "from brax import math\n",
    "from brax.base import Base, Motion, Transform\n",
    "from brax.envs.base import Env, PipelineEnv, State\n",
    "from brax.mjx.base import State as MjxState\n",
    "# from brax.training.agents.apg import train as apg\n",
    "# from brax.training.agents.apg import networks as apg_networks\n",
    "from brax.io import html, mjcf, model\n",
    "from etils import epath\n",
    "from flax import struct\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "from ml_collections import config_dict\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "from jax import vmap\n",
    "import jax.random\n",
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment variable to use GPU rendering:\n",
      "env: MUJOCO_GL=egl\n"
     ]
    }
   ],
   "source": [
    "import distutils.util\n",
    "import os\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "print('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.8\" # 0.9 causes too much lag. \n",
    "from datetime import datetime\n",
    "import functools\n",
    "\n",
    "# Math\n",
    "import jax.numpy as jp\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import config # Analytical gradients work much better with double precision.\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update('jax_default_matmul_precision', jax.lax.Precision.HIGH)\n",
    "from brax import math\n",
    "\n",
    "# Sim\n",
    "import mujoco\n",
    "import mujoco.mjx as mjx\n",
    "\n",
    "# Brax\n",
    "from brax import envs\n",
    "from brax.base import Motion, Transform\n",
    "from brax.io import mjcf\n",
    "from brax.envs.base import PipelineEnv, State\n",
    "from brax.mjx.pipeline import _reformat_contact\n",
    "from brax.training.acme import running_statistics\n",
    "from brax.io import model\n",
    "\n",
    "# Algorithms\n",
    "# from brax.training.agents.apg import train as apg\n",
    "# from brax.training.agents.apg import networks as apg_networks\n",
    "from APGBRAX import train as apg\n",
    "from APGBRAX import networks as apg_networks\n",
    "\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "\n",
    "# Supporting\n",
    "from etils import epath\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "from ml_collections import config_dict\n",
    "from typing import Any, Dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = epath.Path('anybotics_anymal_c/scene_mjx.xml').as_posix()\n",
    "\n",
    "mj_model = mujoco.MjModel.from_xml_path(xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cos_wave(t, step_period, scale):\n",
    "    _cos_wave = -jp.cos(((2*jp.pi)/step_period)*t)\n",
    "    return _cos_wave * (scale/2) + (scale/2)\n",
    "\n",
    "def dcos_wave(t, step_period, scale):\n",
    "    \"\"\" \n",
    "    Derivative of the cos wave, for reference velocity\n",
    "    \"\"\"\n",
    "    return ((scale*jp.pi) / step_period) * jp.sin(((2*jp.pi)/step_period)*t)\n",
    "\n",
    "def make_kinematic_ref(sinusoid, step_k, scale=0.3, dt=1/50):\n",
    "    \"\"\" \n",
    "    Makes trotting kinematics for the 12 leg joints.\n",
    "    step_k is the number of timesteps it takes to raise and lower a given foot.\n",
    "    A gait cycle is 2 * step_k * dt seconds long.\n",
    "    \"\"\"\n",
    "    \n",
    "    _steps = jp.arange(step_k)\n",
    "    step_period = step_k * dt\n",
    "    t = _steps * dt\n",
    "    \n",
    "    wave = sinusoid(t, step_period, scale)\n",
    "    # Commands for one step of an active front leg\n",
    "    fleg_cmd_block = jp.concatenate(\n",
    "        [jp.zeros((step_k, 1)),\n",
    "        wave.reshape(step_k, 1),\n",
    "        -2*wave.reshape(step_k, 1)],\n",
    "        axis=1\n",
    "    )\n",
    "    # Our standing config reverses front and hind legs\n",
    "    h_leg_cmd_bloc = -1 * fleg_cmd_block\n",
    "\n",
    "    block1 = jp.concatenate([\n",
    "        jp.zeros((step_k, 3)),\n",
    "        fleg_cmd_block,\n",
    "        h_leg_cmd_bloc,\n",
    "        jp.zeros((step_k, 3))],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    block2 = jp.concatenate([\n",
    "        fleg_cmd_block,\n",
    "        jp.zeros((step_k, 3)),\n",
    "        jp.zeros((step_k, 3)),\n",
    "        h_leg_cmd_bloc],\n",
    "        axis=1\n",
    "    )\n",
    "    # In one step cycle, both pairs of active legs have inactive and active phases\n",
    "    step_cycle = jp.concatenate([block1, block2], axis=0)\n",
    "    return step_cycle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "  def get_default_rewards_config():\n",
    "    default_config = config_dict.ConfigDict(\n",
    "        dict(\n",
    "            scales=config_dict.ConfigDict(\n",
    "              dict(\n",
    "                min_reference_tracking = -2.5 * 3e-3, # to equalize the magnitude\n",
    "                reference_tracking = -1.0,\n",
    "                feet_height = -1.0\n",
    "                )\n",
    "              )\n",
    "            )\n",
    "    )\n",
    "    return default_config\n",
    "\n",
    "  default_config = config_dict.ConfigDict(\n",
    "      dict(rewards=get_default_rewards_config(),))\n",
    "\n",
    "  return default_config\n",
    "\n",
    "# Math functions from (https://github.com/jiawei-ren/diffmimic)\n",
    "def quaternion_to_matrix(quaternions):\n",
    "    r, i, j, k = quaternions[..., 0], quaternions[..., 1], quaternions[..., 2], quaternions[..., 3]\n",
    "    two_s = 2.0 / (quaternions * quaternions).sum(-1)\n",
    "\n",
    "    o = jp.stack(\n",
    "        (\n",
    "            1 - two_s * (j * j + k * k),\n",
    "            two_s * (i * j - k * r),\n",
    "            two_s * (i * k + j * r),\n",
    "            two_s * (i * j + k * r),\n",
    "            1 - two_s * (i * i + k * k),\n",
    "            two_s * (j * k - i * r),\n",
    "            two_s * (i * k - j * r),\n",
    "            two_s * (j * k + i * r),\n",
    "            1 - two_s * (i * i + j * j),\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    return o.reshape(quaternions.shape[:-1] + (3, 3))\n",
    "\n",
    "def matrix_to_rotation_6d(matrix):\n",
    "    batch_dim = matrix.shape[:-2]\n",
    "    return matrix[..., :2, :].reshape(batch_dim + (6,))\n",
    "\n",
    "def quaternion_to_rotation_6d(quaternion):\n",
    "    return matrix_to_rotation_6d(quaternion_to_matrix(quaternion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrotAnymal(PipelineEnv):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      termination_height: float=0.25,\n",
    "      **kwargs,\n",
    "  ):\n",
    "    step_k = kwargs.pop('step_k', 25)\n",
    "\n",
    "    physics_steps_per_control_step = 10\n",
    "    kwargs['n_frames'] = kwargs.get(\n",
    "        'n_frames', physics_steps_per_control_step)\n",
    "\n",
    "    mj_model = mujoco.MjModel.from_xml_path(xml_path)\n",
    "    kp = 230\n",
    "    mj_model.actuator_gainprm[:, 0] = kp\n",
    "    mj_model.actuator_biasprm[:, 1] = -kp\n",
    "\n",
    "    sys = mjcf.load_model(mj_model)\n",
    "\n",
    "    super().__init__(sys=sys, **kwargs)    \n",
    "    \n",
    "    self.termination_height = termination_height\n",
    "    \n",
    "    self._init_q = mj_model.keyframe('standing').qpos\n",
    "    \n",
    "    self.err_threshold = 0.4 # diffmimic; value from paper.\n",
    "    \n",
    "    self._default_ap_pose = mj_model.keyframe('standing').qpos[7:]\n",
    "    self.reward_config = get_config()\n",
    "\n",
    "    self.action_loc = self._default_ap_pose\n",
    "    self.action_scale = jp.array([0.2, 0.8, 0.8] * 4)\n",
    "    \n",
    "    self.feet_inds = jp.array([21,28,35,42]) # LF, RF, LH, RH\n",
    "\n",
    "    #### Imitation reference\n",
    "    kinematic_ref_qpos = make_kinematic_ref(\n",
    "      cos_wave, step_k, scale=0.3, dt=self.dt)\n",
    "    kinematic_ref_qvel = make_kinematic_ref(\n",
    "      dcos_wave, step_k, scale=0.3, dt=self.dt)\n",
    "    \n",
    "    self.l_cycle = jp.array(kinematic_ref_qpos.shape[0])\n",
    "    \n",
    "    # Expand to entire state space.\n",
    "\n",
    "    kinematic_ref_qpos += self._default_ap_pose\n",
    "    ref_qs = np.tile(self._init_q.reshape(1, 19), (self.l_cycle, 1))\n",
    "    ref_qs[:, 7:] = kinematic_ref_qpos\n",
    "    self.kinematic_ref_qpos = jp.array(ref_qs)\n",
    "    \n",
    "    ref_qvels = np.zeros((self.l_cycle, 18))\n",
    "    ref_qvels[:, 6:] = kinematic_ref_qvel\n",
    "    self.kinematic_ref_qvel = jp.array(ref_qvels)\n",
    "\n",
    "    # Can decrease jit time and training wall-clock time significantly.\n",
    "    self.pipeline_step = jax.checkpoint(self.pipeline_step, \n",
    "      policy=jax.checkpoint_policies.dots_with_no_batch_dims_saveable)\n",
    "    \n",
    "  def reset(self, rng: jax.Array) -> State:\n",
    "    # Deterministic init\n",
    "\n",
    "    qpos = jp.array(self._init_q)\n",
    "    qvel = jp.zeros(18)\n",
    "    \n",
    "    data = self.pipeline_init(qpos, qvel)\n",
    "\n",
    "    # Position onto ground\n",
    "    pen = jp.min(data.contact.dist)\n",
    "    qpos = qpos.at[2].set(qpos[2] - pen)\n",
    "    data = self.pipeline_init(qpos, qvel)\n",
    "\n",
    "    state_info = {\n",
    "        'rng': rng,\n",
    "        'steps': 0.0,\n",
    "        'reward_tuple': {\n",
    "            'reference_tracking': 0.0,\n",
    "            'min_reference_tracking': 0.0,\n",
    "            'feet_height': 0.0\n",
    "        },\n",
    "        'last_action': jp.zeros(12), # from MJX tutorial.\n",
    "        'kinematic_ref': jp.zeros(19),\n",
    "    }\n",
    "\n",
    "    x, xd = data.x, data.xd\n",
    "    obs = self._get_obs(data.qpos, x, xd, state_info)\n",
    "    reward, done = jp.zeros(2)\n",
    "    metrics = {}\n",
    "    for k in state_info['reward_tuple']:\n",
    "      metrics[k] = state_info['reward_tuple'][k]\n",
    "    state = State(data, obs, reward, done, metrics, state_info)\n",
    "    return jax.lax.stop_gradient(state)\n",
    "  \n",
    "  def step(self, state: State, action: jax.Array) -> State:\n",
    "    action = jp.clip(action, -1, 1) # Raw action\n",
    "\n",
    "    action = self.action_loc + (action * self.action_scale)\n",
    "\n",
    "    data = self.pipeline_step(state.pipeline_state, action)\n",
    "    \n",
    "    # jax.debug.print('steps cycle: {}',state.info['steps']%self.l_cycle)\n",
    "    # jax.debug.print('steps info: {}',state.info['steps'])\n",
    "    \n",
    "    \n",
    "    ref_qpos = self.kinematic_ref_qpos[jp.array(state.info['steps']%self.l_cycle, int)]\n",
    "    ref_qvel = self.kinematic_ref_qvel[jp.array(state.info['steps']%self.l_cycle, int)]\n",
    "    \n",
    "    # Calculate maximal coordinates\n",
    "    ref_data = data.replace(qpos=ref_qpos, qvel=ref_qvel)\n",
    "    ref_data = mjx.forward(self.sys, ref_data)\n",
    "    ref_x, ref_xd = ref_data.x, ref_data.xd\n",
    "\n",
    "    state.info['kinematic_ref'] = ref_qpos\n",
    "\n",
    "    # observation data\n",
    "    x, xd = data.x, data.xd\n",
    "    obs = self._get_obs(data.qpos, x, xd, state.info)\n",
    "\n",
    "    # Terminate if flipped over or fallen down.\n",
    "    done = 0.0\n",
    "    done = jp.where(x.pos[0, 2] < self.termination_height, 1.0, done)\n",
    "    up = jp.array([0.0, 0.0, 1.0])\n",
    "    done = jp.where(jp.dot(math.rotate(up, x.rot[0]), up) < 0, 1.0, done)\n",
    "\n",
    "    # reward\n",
    "    reward_tuple = {\n",
    "        'reference_tracking': (\n",
    "          self._reward_reference_tracking(x, xd, ref_x, ref_xd)\n",
    "          * self.reward_config.rewards.scales.reference_tracking\n",
    "        ),\n",
    "        'min_reference_tracking': (\n",
    "          self._reward_min_reference_tracking(ref_qpos, ref_qvel, state)\n",
    "          * self.reward_config.rewards.scales.min_reference_tracking\n",
    "        ),\n",
    "        'feet_height': (\n",
    "          self._reward_feet_height(data.geom_xpos[self.feet_inds][:, 2]\n",
    "                                   ,ref_data.geom_xpos[self.feet_inds][:, 2])\n",
    "          * self.reward_config.rewards.scales.feet_height\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    reward = sum(reward_tuple.values())\n",
    "\n",
    "    # state management\n",
    "    state.info['reward_tuple'] = reward_tuple\n",
    "    state.info['last_action'] = action # used for observation. \n",
    "\n",
    "    for k in state.info['reward_tuple'].keys():\n",
    "      state.metrics[k] = state.info['reward_tuple'][k]\n",
    "\n",
    "    state = state.replace(\n",
    "        pipeline_state=data, obs=obs, reward=reward,\n",
    "        done=done)\n",
    "    \n",
    "    #### Reset state to reference if it gets too far\n",
    "    error = (((x.pos - ref_x.pos) ** 2).sum(-1)**0.5).mean()\n",
    "    to_reference = jp.where(error > self.err_threshold, 1.0, 0.0)\n",
    "\n",
    "    to_reference = jp.array(to_reference, dtype=int) # keeps output types same as input. \n",
    "    ref_data = self.mjx_to_brax(ref_data)\n",
    "\n",
    "    data = jax.tree_util.tree_map(lambda x, y: \n",
    "                                  jp.array((1-to_reference)*x + to_reference*y, x.dtype), data, ref_data)\n",
    "    \n",
    "    x, xd = data.x, data.xd # Data may have changed.\n",
    "    obs = self._get_obs(data.qpos, x, xd, state.info)\n",
    "    \n",
    "    return state.replace(pipeline_state=data, obs=obs)\n",
    "    \n",
    "  def _get_obs(self, qpos: jax.Array, x: Transform, xd: Motion,\n",
    "               state_info: Dict[str, Any]) -> jax.Array:\n",
    "\n",
    "    inv_base_orientation = math.quat_inv(x.rot[0])\n",
    "    local_rpyrate = math.rotate(xd.ang[0], inv_base_orientation)\n",
    "\n",
    "    obs_list = []\n",
    "    # yaw rate\n",
    "    obs_list.append(jp.array([local_rpyrate[2]]) * 0.25)\n",
    "    # projected gravity\n",
    "    obs_list.append(\n",
    "        math.rotate(jp.array([0.0, 0.0, -1.0]), inv_base_orientation))\n",
    "    # motor angles\n",
    "    angles = qpos[7:19]\n",
    "    obs_list.append(angles - self._default_ap_pose)\n",
    "    # last action\n",
    "    obs_list.append(state_info['last_action'])\n",
    "    # kinematic reference\n",
    "    kin_ref = self.kinematic_ref_qpos[jp.array(state_info['steps']%self.l_cycle, int)]\n",
    "    obs_list.append(kin_ref[7:]) # First 7 indicies are fixed\n",
    "\n",
    "    obs = jp.clip(jp.concatenate(obs_list), -100.0, 100.0)\n",
    "\n",
    "    return obs\n",
    "  \n",
    "  def mjx_to_brax(self, data):\n",
    "    \"\"\" \n",
    "    Apply the brax wrapper on the core MJX data structure.\n",
    "    \"\"\"\n",
    "    q, qd = data.qpos, data.qvel\n",
    "    x = Transform(pos=data.xpos[1:], rot=data.xquat[1:])\n",
    "    cvel = Motion(vel=data.cvel[1:, 3:], ang=data.cvel[1:, :3])\n",
    "    offset = data.xpos[1:, :] - data.subtree_com[self.sys.body_rootid[1:]]\n",
    "    offset = Transform.create(pos=offset)\n",
    "    xd = offset.vmap().do(cvel)\n",
    "    data = _reformat_contact(self.sys, data)\n",
    "    return data.replace(q=q, qd=qd, x=x, xd=xd)\n",
    "\n",
    "\n",
    "  # ------------ reward functions----------------\n",
    "  def _reward_reference_tracking(self, x, xd, ref_x, ref_xd):\n",
    "    \"\"\"\n",
    "    Rewards based on inertial-frame body positions.\n",
    "    Notably, we use a high-dimension representation of orientation.\n",
    "    \"\"\"\n",
    "\n",
    "    f = lambda x, y: ((x - y) ** 2).sum(-1).mean()\n",
    "\n",
    "    _mse_pos = f(x.pos,  ref_x.pos)\n",
    "    _mse_rot = f(quaternion_to_rotation_6d(x.rot),\n",
    "                 quaternion_to_rotation_6d(ref_x.rot))\n",
    "    _mse_vel = f(xd.vel, ref_xd.vel)\n",
    "    _mse_ang = f(xd.ang, ref_xd.ang)\n",
    "\n",
    "    # Tuned to be about the same size.\n",
    "    return _mse_pos      \\\n",
    "      + 0.1 * _mse_rot   \\\n",
    "      + 0.01 * _mse_vel  \\\n",
    "      + 0.001 * _mse_ang\n",
    "\n",
    "  def _reward_min_reference_tracking(self, ref_qpos, ref_qvel, state):\n",
    "    \"\"\" \n",
    "    Using minimal coordinates. Improves accuracy of joint angle tracking.\n",
    "    \"\"\"\n",
    "    pos = jp.concatenate([\n",
    "      state.pipeline_state.qpos[:3],\n",
    "      state.pipeline_state.qpos[7:]])\n",
    "    pos_targ = jp.concatenate([\n",
    "      ref_qpos[:3],\n",
    "      ref_qpos[7:]])\n",
    "    pos_err = jp.linalg.norm(pos_targ - pos)\n",
    "    vel_err = jp.linalg.norm(state.pipeline_state.qvel- ref_qvel)\n",
    "\n",
    "    return pos_err + vel_err\n",
    "\n",
    "  def _reward_feet_height(self, feet_pos, feet_pos_ref):\n",
    "    return jp.sum(jp.abs(feet_pos - feet_pos_ref)) # try to drive it to 0 using the l1 norm.\n",
    "\n",
    "envs.register_environment('trotting_anymal', TrotAnymal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Option(timestep=Array(0.002, dtype=float64, weak_type=True), impratio=Array(100., dtype=float64, weak_type=True), tolerance=Array(1.e-08, dtype=float64, weak_type=True), ls_tolerance=Array(0.01, dtype=float64, weak_type=True), gravity=Array([ 0.  ,  0.  , -9.81], dtype=float64), wind=Array([0., 0., 0.], dtype=float64), density=Array(0., dtype=float64, weak_type=True), viscosity=Array(0., dtype=float64, weak_type=True), has_fluid_params=False, integrator=<IntegratorType.EULER: 0>, cone=<ConeType.PYRAMIDAL: 0>, jacobian=<JacobianType.AUTO: 2>, solver=<SolverType.NEWTON: 2>, iterations=1, ls_iterations=6, disableflags=<DisableBit.EULERDAMP: 16384>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = envs.get_environment(\"trotting_anymal\", step_k = 13)\n",
    "eval_env = envs.get_environment(\"trotting_anymal\", step_k = 13)\n",
    "\n",
    "env.sys.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.sys.actuator_gainprm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fn = functools.partial(\n",
    "#     ppo.train, num_timesteps=10_000_000, num_evals=10, reward_scaling=0.1,\n",
    "#     episode_length=1000, normalize_observations=True, action_repeat=1,\n",
    "#     unroll_length=10, num_minibatches=32, num_updates_per_batch=8,\n",
    "#     discounting=0.97, learning_rate=3e-4, entropy_cost=1e-3, num_envs=1024,\n",
    "#     batch_size=1024, seed=0)\n",
    "\n",
    "# x_data = []\n",
    "# y_data = []\n",
    "# ydataerr = []\n",
    "# env = envs.get_environment(\"trotting_anymal\", step_k = 13)\n",
    "\n",
    "# def progress(num_steps, metrics):\n",
    "#   x_data.append(num_steps)\n",
    "#   y_data.append(metrics['eval/episode_reward'])\n",
    "#   ydataerr.append(metrics['eval/episode_reward_std'])\n",
    "\n",
    "# make_inference_fn, params, _= train_fn(environment=env, progress_fn=progress)\n",
    "\n",
    "# plt.errorbar(x_data, y_data, yerr=ydataerr)\n",
    "# plt.xlabel('# environment steps')\n",
    "# plt.ylabel('reward per episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_networks_factory = functools.partial(\n",
    "    apg_networks.make_apg_networks,\n",
    "    hidden_layer_sizes=(256, 128)\n",
    ")\n",
    "\n",
    "epochs = 499\n",
    "\n",
    "\n",
    "train_fn = functools.partial(apg.train,\n",
    "                             episode_length=1000,\n",
    "                             policy_updates=epochs,\n",
    "                             horizon_length=32,\n",
    "                             num_envs=64,\n",
    "                             learning_rate=1.5e-4,\n",
    "                             schedule_decay=0.995,\n",
    "                             num_eval_envs=64,\n",
    "                             num_evals=10 + 1,\n",
    "                             use_float64=True,\n",
    "                             normalize_observations=True,\n",
    "                             network_factory=make_networks_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1348/966135583.py:15: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "  plt.xlim([0, it* 1.25])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after metrics\n",
      "after scramble time\n",
      "it 0\n",
      "before epoch\n",
      "reached the minibatch step:{} 1\n",
      "loss\n",
      "after f\n",
      "env step\n",
      "Actions: {} Traced<ShapedArray(float64[64,12])>with<DynamicJaxprTrace(level=4/1)>\n",
      "New state obs: {} Traced<ShapedArray(float64[64,40])>with<DynamicJaxprTrace(level=4/1)>\n",
      "after loss\n",
      "after the minibatch_step\n",
      "jax trainng epoch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n",
      "reached the minibatch step:1\n",
      "loss3\n",
      "sssf3\n",
      "env step3\n",
      "sssloss3\n",
      "after the minibatch step:1\n"
     ]
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "ydataerr = []\n",
    "times = [datetime.now()]\n",
    "\n",
    "def progress(it, metrics):\n",
    "  times.append(datetime.now())\n",
    "  x_data.append(it)\n",
    "  y_data.append(metrics['eval/episode_reward'])\n",
    "  ydataerr.append(metrics['eval/episode_reward_std'])\n",
    "  #y_pose_error.append(metrics['eval/episode_pose_error'])  # capture pose error\n",
    "  \n",
    "  plt.figure(figsize=(10, 5))\n",
    "  plt.subplot(1, 2, 1) \n",
    "  plt.xlim([0, it* 1.25])\n",
    "  plt.ylim([100, 200])\n",
    "\n",
    "  plt.xlabel('# environment steps')\n",
    "  plt.ylabel('reward per episode')\n",
    "  plt.title(f'Latest Reward: {y_data[-1]:.3f}')\n",
    "  plt.plot(x_data, y_data, '-o')\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "# Each foot contacts the ground twice/sec.\n",
    "env = envs.get_environment(\"trotting_anymal\", step_k = 13)\n",
    "eval_env = envs.get_environment(\"trotting_anymal\", step_k = 13)\n",
    "\n",
    "make_inference_fn, params, _= train_fn(environment=env,\n",
    "                                       progress_fn=progress,\n",
    "                                       eval_env=eval_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newBrax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
