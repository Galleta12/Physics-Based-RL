{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import functools\n",
    "from IPython.display import HTML\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Sequence, Tuple, Union\n",
    "from brax import base\n",
    "from brax import envs\n",
    "from brax import math\n",
    "from brax.base import Base, Motion, Transform\n",
    "from brax.envs.base import Env, PipelineEnv, State\n",
    "from brax.mjx.base import State as MjxState\n",
    "# from brax.training.agents.apg import train as apg\n",
    "# from brax.training.agents.apg import networks as apg_networks\n",
    "from brax.io import html, mjcf, model\n",
    "from etils import epath\n",
    "from flax import struct\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "from ml_collections import config_dict\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "from jax import vmap\n",
    "import jax.random\n",
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SimpleConverter import SimpleConverter\n",
    "from agent_mimic_env.agent_template import HumanoidTemplate\n",
    "from agent_mimic_env.agent_eval_template import HumanoidEvalTemplate\n",
    "from agent_mimic_env.agent_training_template import HumanoidTrainTemplate\n",
    "from utils.util_data import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent_mimic_env\n",
    "from agent_mimic_env import register_mimic_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment variable to use GPU rendering:\n",
      "env: MUJOCO_GL=egl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import distutils.util\n",
    "import os\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "print('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from box import Box\n",
    "# Path to your YAML file\n",
    "yaml_file_path = 'config_params/punch.yaml'\n",
    "# Load the YAML file\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    args = Box(yaml.safe_load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_mimic_env.pds_controllers_agents import feedback_pd_controller, stable_pd_controller_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_replay,env_eval, env=register_mimic_env(args)\n",
    "\n",
    "#for the eval here we run the trained policy\n",
    "jit_reset = jax.jit(env_eval.reset)\n",
    "jit_step = jax.jit(env_eval.step)\n",
    "\n",
    "env_eval.set_pd_callback(stable_pd_controller_action)\n",
    "\n",
    "env.set_pd_callback(stable_pd_controller_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = jit_reset(jax.random.PRNGKey(0))\n",
    "# rollout = [state.pipeline_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLAPGBRAX import train as apg\n",
    "from RLAPGBRAX import networks as apg_networks\n",
    "# import brax\n",
    "# from brax.training.agents.apg import train as apg\n",
    "# from brax.training.agents.apg import networks as apg_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "episode_len = env_eval.rollout_lenght\n",
    "print(episode_len)\n",
    "print(env.err_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Data' object has no attribute 'ncon'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m   plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     64\u001b[0m   plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 66\u001b[0m make_inference_fn, params, _\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mprogress_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime to jit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtimes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime to train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtimes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/Physics-Based-RL/RLAPGBRAX/train.py:136\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(environment, episode_length, policy_updates, horizon_length, num_envs, num_evals, action_repeat, max_devices_per_host, num_eval_envs, learning_rate, adam_b, use_schedule, use_float64, schedule_decay, seed, max_gradient_norm, normalize_observations, deterministic_eval, network_factory, progress_fn, eval_env, randomization_fn)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize_observations:\n\u001b[1;32m    134\u001b[0m   normalize \u001b[38;5;241m=\u001b[39m running_statistics\u001b[38;5;241m.\u001b[39mnormalize\n\u001b[1;32m    135\u001b[0m apg_network \u001b[38;5;241m=\u001b[39m network_factory(\n\u001b[0;32m--> 136\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_size\u001b[49m,\n\u001b[1;32m    137\u001b[0m     env\u001b[38;5;241m.\u001b[39maction_size,\n\u001b[1;32m    138\u001b[0m     preprocess_observations_fn\u001b[38;5;241m=\u001b[39mnormalize)\n\u001b[1;32m    139\u001b[0m make_policy \u001b[38;5;241m=\u001b[39m apg_networks\u001b[38;5;241m.\u001b[39mmake_inference_fn(apg_network)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_schedule:\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxMujoco/lib/python3.11/site-packages/brax/envs/base.py:193\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    192\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, name)\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxMujoco/lib/python3.11/site-packages/brax/envs/base.py:193\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    192\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, name)\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxMujoco/lib/python3.11/site-packages/brax/envs/base.py:193\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    192\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, name)\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxMujoco/lib/python3.11/site-packages/brax/envs/base.py:140\u001b[0m, in \u001b[0;36mPipelineEnv.observation_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobservation_size\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    139\u001b[0m   rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m   reset_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m reset_state\u001b[38;5;241m.\u001b[39mobs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/Physics-Based-RL/agent_mimic_env/agent_template.py:132\u001b[0m, in \u001b[0;36mHumanoidTemplate.reset\u001b[0;34m(self, rng)\u001b[0m\n\u001b[1;32m    130\u001b[0m reward, done, zero \u001b[38;5;241m=\u001b[39m jp\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#start at the initial state\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reference_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m       \n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# qvel = jp.zeros(self.sys.nv)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# qpos =  self.sys.qpos0\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# data = self.pipeline_init(qpos,qvel) \u001b[39;00m\n\u001b[1;32m    137\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_index\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpose_error\u001b[39m\u001b[38;5;124m'\u001b[39m: zero, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfall\u001b[39m\u001b[38;5;124m'\u001b[39m: zero}\n",
      "File \u001b[0;32m~/workspace/Physics-Based-RL/agent_mimic_env/agent_template.py:114\u001b[0m, in \u001b[0;36mHumanoidTemplate.get_reference_state\u001b[0;34m(self, step_index)\u001b[0m\n\u001b[1;32m    112\u001b[0m ref_qv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_trajectory_qvel[step_index]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m#now I will return a state depending on the index and the reference trajectory\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_qp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mref_qv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxMujoco/lib/python3.11/site-packages/brax/envs/base.py:119\u001b[0m, in \u001b[0;36mPipelineEnv.pipeline_init\u001b[0;34m(self, q, qd, act)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipeline_init\u001b[39m(\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m, q: jax\u001b[38;5;241m.\u001b[39mArray, qd: jax\u001b[38;5;241m.\u001b[39mArray, act: Optional[jax\u001b[38;5;241m.\u001b[39mArray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m base\u001b[38;5;241m.\u001b[39mState:\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes the pipeline state.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_debug\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxMujoco/lib/python3.11/site-packages/brax/mjx/pipeline.py:77\u001b[0m, in \u001b[0;36minit\u001b[0;34m(sys, q, qd, act, unused_debug)\u001b[0m\n\u001b[1;32m     74\u001b[0m offset \u001b[38;5;241m=\u001b[39m Transform\u001b[38;5;241m.\u001b[39mcreate(pos\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m     75\u001b[0m xd \u001b[38;5;241m=\u001b[39m offset\u001b[38;5;241m.\u001b[39mvmap()\u001b[38;5;241m.\u001b[39mdo(cvel)\n\u001b[0;32m---> 77\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m_reformat_contact\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m State(q\u001b[38;5;241m=\u001b[39mq, qd\u001b[38;5;241m=\u001b[39mqd, x\u001b[38;5;241m=\u001b[39mx, xd\u001b[38;5;241m=\u001b[39mxd, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxMujoco/lib/python3.11/site-packages/brax/mjx/pipeline.py:28\u001b[0m, in \u001b[0;36m_reformat_contact\u001b[0;34m(sys, data)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reformat_contact\u001b[39m(sys: System, data: State) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m State:\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reformats the mjx.Contact into a brax.base.Contact.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcontact \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncon\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m     31\u001b[0m   elasticity \u001b[38;5;241m=\u001b[39m jp\u001b[38;5;241m.\u001b[39mzeros(data\u001b[38;5;241m.\u001b[39mcontact\u001b[38;5;241m.\u001b[39mpos\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Data' object has no attribute 'ncon'"
     ]
    }
   ],
   "source": [
    "# Reconstruct the trotting inference function\n",
    "make_networks_factory = functools.partial(\n",
    "    apg_networks.make_apg_networks,\n",
    "    hidden_layer_sizes=(512, 256)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "\n",
    "train_fn = functools.partial(apg.train,\n",
    "                             episode_length=episode_len-1,\n",
    "                             policy_updates=epochs,\n",
    "                             horizon_length=32,\n",
    "                             num_envs=256,\n",
    "                             learning_rate=args.lr,\n",
    "                             max_gradient_norm=args.max_grad_norm,\n",
    "                             schedule_decay=0.995,\n",
    "                             num_eval_envs=args.num_eval_envs,\n",
    "                             num_evals=args.max_it+1,\n",
    "                             use_float64=True,\n",
    "                             normalize_observations=True,\n",
    "                             seed=0,\n",
    "                             network_factory=make_networks_factory)\n",
    "\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "ydataerr = []\n",
    "y_pose_error = []  # to store pose error\n",
    "times = [datetime.now()]\n",
    "max_y_rewards, min_y_rewards = 0, -5\n",
    "def progress(num_steps, metrics):\n",
    "  \n",
    "  #print(num_steps)\n",
    "  times.append(datetime.now())\n",
    "  x_data.append(num_steps)\n",
    "  y_data.append(metrics['eval/episode_reward'])\n",
    "  ydataerr.append(metrics['eval/episode_reward_std'])\n",
    "  y_pose_error.append(metrics['eval/episode_pose_error'])  # capture pose error\n",
    "  \n",
    "  plt.figure(figsize=(10, 5))\n",
    "  plt.subplot(1, 2, 1) \n",
    "  plt.xlim([0, num_steps* 1.25])\n",
    "  plt.ylim([max_y_rewards, min_y_rewards])\n",
    "\n",
    "  plt.xlabel('# environment steps')\n",
    "  plt.ylabel('reward per episode')\n",
    "  plt.title(f'Latest Reward: {y_data[-1]:.3f}')\n",
    "  plt.plot(x_data, y_data, '-o')\n",
    "  \n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.xlim([0, num_steps* 1.25])\n",
    "  plt.ylim([min(y_pose_error) * 0.9, max(y_pose_error) * 1.1])\n",
    "  plt.xlabel('# Environment Steps')\n",
    "  plt.ylabel('Pose Error per Episode')\n",
    "  plt.title(f'Latest Pose Error: {y_pose_error[-1]:.3f}')\n",
    "  plt.plot(x_data, y_pose_error, '-o')\n",
    "  \n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  \n",
    "make_inference_fn, params, _= train_fn(environment=env_eval,\n",
    "                                       progress_fn=progress,\n",
    "                                       eval_env=env_eval)\n",
    "\n",
    "print(f'time to jit: {times[1] - times[0]}')\n",
    "print(f'time to train: {times[-1] - times[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxMujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
