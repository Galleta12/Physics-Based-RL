{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import functools\n",
    "from IPython.display import HTML\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Sequence, Tuple, Union\n",
    "from brax import base\n",
    "from brax import envs\n",
    "from brax import math\n",
    "from brax.base import Base, Motion, Transform\n",
    "from brax.envs.base import Env, PipelineEnv, State\n",
    "from brax.mjx.base import State as MjxState\n",
    "from brax.training.agents.apg import train as apg\n",
    "from brax.training.agents.apg import networks as apg_networks\n",
    "from brax.io import html, mjcf, model\n",
    "from etils import epath\n",
    "from flax import struct\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "from ml_collections import config_dict\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "from jax import vmap\n",
    "import jax.random\n",
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SimpleConverter import SimpleConverter\n",
    "from agent_mimic_env.agent_template import HumanoidTemplate\n",
    "from agent_mimic_env.agent_eval_template import HumanoidEvalTemplate\n",
    "from utils.util_data import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent_mimic_env\n",
    "from agent_mimic_env import register_mimic_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment variable to use GPU rendering:\n",
      "env: MUJOCO_GL=egl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import distutils.util\n",
    "import os\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "print('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from box import Box\n",
    "# Path to your YAML file\n",
    "yaml_file_path = 'config_params/punch.yaml'\n",
    "# Load the YAML file\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    args = Box(yaml.safe_load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_mimic_env.pds_controllers_agents import feedback_pd_controller, stable_pd_controller_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_replay,env_eval=register_mimic_env(args)\n",
    "\n",
    "#for the eval\n",
    "jit_reset = jax.jit(env_eval.reset)\n",
    "jit_step = jax.jit(env_eval.step)\n",
    "env_eval.set_pd_callback(stable_pd_controller_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "rollout = [state.pipeline_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLALG import agent_diffmimic as diff\n",
    "from RLALG import agent_ppo as ppo\n",
    "from RLALG import ppo_angent_networks as ppo_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function make_ppo_networks at 0x7ff66444c720>, policy_hidden_layer_sizes=(512, 256), value_hidden_layer_sizes=(512, 256))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_networks_factory = functools.partial(\n",
    "    ppo_networks.make_ppo_networks,\n",
    "        policy_hidden_layer_sizes=(512,256),\n",
    "        value_hidden_layer_sizes=(512,256))\n",
    "make_networks_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "episode_len = env_eval.rollout_lenght\n",
    "print(episode_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of eval after init 9\n",
      "env step per traning step 61440\n",
      "training steps per epoch 1\n",
      "Episode lenght 64\n",
      "Env size 193\n"
     ]
    }
   ],
   "source": [
    "train_fn = functools.partial(\n",
    "    ppo.train,\n",
    "    num_timesteps=100_000,  # Total timesteps for training\n",
    "    #num_timesteps=100_000_000,  # Total timesteps for training\n",
    "    num_evals=10,\n",
    "    num_eval_envs=args.num_eval_envs,\n",
    "    reward_scaling=1,\n",
    "    episode_length=episode_len-1,  # Ensure episode_len is defined\n",
    "    normalize_observations=args.normalize_observations,\n",
    "    action_repeat=1,\n",
    "    unroll_length=10,\n",
    "    num_minibatches=24,  # Adjusted number of minibatches\n",
    "    num_updates_per_batch=4,\n",
    "    discounting=0.97,  # Discount factor Î³\n",
    "    learning_rate=3.0e-4,\n",
    "    entropy_cost=1e-2,\n",
    "    num_envs=256,  # Changed number of parallel environments to match batch size\n",
    "    batch_size=256,  # Adjusted batch size\n",
    "    network_factory=make_networks_factory,\n",
    "    seed=0  # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "ydataerr = []\n",
    "y_pose_error = []  # to store pose error\n",
    "times = [datetime.now()]\n",
    "max_y_rewards, min_y_rewards = 0, -5\n",
    "def progress(num_steps, metrics):\n",
    "  \n",
    "  #print(num_steps)\n",
    "  times.append(datetime.now())\n",
    "  x_data.append(num_steps)\n",
    "  y_data.append(metrics['eval/episode_reward'])\n",
    "  ydataerr.append(metrics['eval/episode_reward_std'])\n",
    "  y_pose_error.append(metrics['eval/episode_pose_error'])  # capture pose error\n",
    "  \n",
    "  plt.figure(figsize=(10, 5))\n",
    "  plt.subplot(1, 2, 1) \n",
    "  plt.xlim([0, num_steps* 1.25])\n",
    "  plt.ylim([max_y_rewards, min_y_rewards])\n",
    "\n",
    "  plt.xlabel('# environment steps')\n",
    "  plt.ylabel('reward per episode')\n",
    "  plt.title(f'Latest Reward: {y_data[-1]:.3f}')\n",
    "  plt.plot(x_data, y_data, '-o')\n",
    "  \n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.xlim([0, num_steps* 1.25])\n",
    "  plt.ylim([min(y_pose_error) * 0.9, max(y_pose_error) * 1.1])\n",
    "  plt.xlabel('# Environment Steps')\n",
    "  plt.ylabel('Pose Error per Episode')\n",
    "  plt.title(f'Latest Pose Error: {y_pose_error[-1]:.3f}')\n",
    "  plt.plot(x_data, y_pose_error, '-o')\n",
    "  \n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  \n",
    "make_inference_fn, params, _= train_fn(environment=env_eval,\n",
    "                                       progress_fn=progress,\n",
    "                                       eval_env=env_eval)\n",
    "\n",
    "print(f'time to jit: {times[1] - times[0]}')\n",
    "print(f'time to train: {times[-1] - times[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a directory if it does not exist\n",
    "os.makedirs('model_checkpoints', exist_ok=True)\n",
    "\n",
    "# Save in the subdirectory\n",
    "model_path = 'model_checkpoints/model_punch4_policy'\n",
    "model.save_params(model_path, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.load_params(model_path)\n",
    "\n",
    "inference_fn = make_inference_fn(params)\n",
    "jit_inference_fn = jax.jit(inference_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the state\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = jit_reset(rng)\n",
    "rollout = [state.pipeline_state]\n",
    "\n",
    "# grab a trajectory\n",
    "n_steps = 500\n",
    "render_every = 2\n",
    "\n",
    "for i in range(n_steps):\n",
    "  act_rng, rng = jax.random.split(rng)\n",
    "  ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "  state = jit_step(state, ctrl)\n",
    "  rollout.append(state.pipeline_state)\n",
    "\n",
    "  if state.done:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html.render(env_eval.sys.replace(dt=env_eval.dt), rollout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Convert rollout to a numpy array if it's not already (assumes it's convertible directly)\n",
    "rollout_array = np.array(rollout)\n",
    "os.makedirs('rollout_check', exist_ok=True)\n",
    "# Save the numpy array to a .npy file\n",
    "np.save('rollout_check/rollout_please4.npy', rollout_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
