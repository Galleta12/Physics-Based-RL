{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import functools\n",
    "from IPython.display import HTML\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Sequence, Tuple, Union\n",
    "from brax import base\n",
    "from brax import envs\n",
    "from brax import math\n",
    "from brax.base import Base, Motion, Transform\n",
    "from brax.envs.base import Env, PipelineEnv, State\n",
    "from brax.mjx.base import State as MjxState\n",
    "# from brax.training.agents.apg import train as apg\n",
    "# from brax.training.agents.apg import networks as apg_networks\n",
    "from brax.io import html, mjcf, model\n",
    "from etils import epath\n",
    "from flax import struct\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "from ml_collections import config_dict\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "from jax import vmap\n",
    "import jax.random\n",
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment variable to use GPU rendering:\n",
      "env: MUJOCO_GL=egl\n"
     ]
    }
   ],
   "source": [
    "import distutils.util\n",
    "import os\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "print('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.8\" # 0.9 causes too much lag. \n",
    "from datetime import datetime\n",
    "import functools\n",
    "\n",
    "# Math\n",
    "import jax.numpy as jp\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import config # Analytical gradients work much better with double precision.\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update('jax_default_matmul_precision', jax.lax.Precision.HIGH)\n",
    "from brax import math\n",
    "\n",
    "# Sim\n",
    "import mujoco\n",
    "import mujoco.mjx as mjx\n",
    "\n",
    "# Brax\n",
    "from brax import envs\n",
    "from brax.base import Motion, Transform\n",
    "from brax.io import mjcf\n",
    "from brax.envs.base import PipelineEnv, State\n",
    "from brax.mjx.pipeline import _reformat_contact\n",
    "from brax.training.acme import running_statistics\n",
    "from brax.io import model\n",
    "\n",
    "# Algorithms\n",
    "# from brax.training.agents.apg import train as apg\n",
    "# from brax.training.agents.apg import networks as apg_networks\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "\n",
    "# Supporting\n",
    "from etils import epath\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "from ml_collections import config_dict\n",
    "from typing import Any, Dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SimpleConverter import SimpleConverter\n",
    "from agent_mimic_env.agent_template import HumanoidTemplate\n",
    "from agent_mimic_env.agent_eval_template import HumanoidEvalTemplate\n",
    "from agent_mimic_env.agent_training_template import HumanoidTrainTemplate\n",
    "from agent_mimic_env.agent_test_apg import HumanoidAPGTest\n",
    "from utils.util_data import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent_mimic_env\n",
    "from agent_mimic_env import register_mimic_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from box import Box\n",
    "# Path to your YAML file\n",
    "yaml_file_path = 'config_params/punch.yaml'\n",
    "# Load the YAML file\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    args = Box(yaml.safe_load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_mimic_env.pds_controllers_agents import feedback_pd_controller, stable_pd_controller_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qpos init (65, 35)\n",
      "qvel init (65, 34)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env_replay,env_eval, env,env_apg=register_mimic_env(args)\n",
    "\n",
    "#for the eval here we run the trained policy\n",
    "jit_reset = jax.jit(env_eval.reset)\n",
    "jit_step = jax.jit(env_eval.step)\n",
    "\n",
    "env_eval.set_pd_callback(stable_pd_controller_action)\n",
    "\n",
    "env.set_pd_callback(stable_pd_controller_action)\n",
    "#env_apg.set_pd_callback(stable_pd_controller_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "episode_len = env_eval.rollout_lenght\n",
    "print(episode_len)\n",
    "print(env.err_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from APGBRAX import train as apg\n",
    "from APGBRAX import networks as apg_networks\n",
    "\n",
    "# from brax.training.agents.apg import train as apg\n",
    "# from brax.training.agents.apg import networks as apg_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_networks_factory = functools.partial(\n",
    "#     apg_networks.make_apg_networks,\n",
    "#     hidden_layer_sizes=(512,256)\n",
    "# )\n",
    "# make_networks_factory \n",
    "\n",
    "make_networks_factory = functools.partial(\n",
    "    apg_networks.make_apg_networks,\n",
    "    hidden_layer_sizes=(512, 256)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # epochs = 1000\n",
    "\n",
    "# # train_fn = functools.partial(apg.train,\n",
    "# #                              episode_length=episode_len-1,\n",
    "# #                              policy_updates=epochs,\n",
    "# #                              horizon_length=32,\n",
    "# #                              num_envs=args.num_envs,\n",
    "# #                              learning_rate=args.lr,\n",
    "# #                              schedule_decay=0.995,\n",
    "# #                              num_eval_envs=args.num_eval_envs,\n",
    "# #                              num_evals=10 + 1,\n",
    "# #                              use_schedule=args.use_lr_scheduler,\n",
    "# #                              use_float64=True,\n",
    "# #                              normalize_observations=args.normalize_observations,\n",
    "# #                              max_gradient_norm=args.max_grad_norm,\n",
    "# #                              network_factory=make_networks_factory,\n",
    "# #                              seed=args.seed)\n",
    "\n",
    "\n",
    "# epochs = 499\n",
    "\n",
    "\n",
    "# train_fn = functools.partial(apg.train,\n",
    "#                              episode_length=episode_len-1,\n",
    "#                              policy_updates=epochs,\n",
    "#                              horizon_length=15,\n",
    "#                              num_envs=264,\n",
    "#                              learning_rate=1.5e-4,\n",
    "#                              schedule_decay=0.995,\n",
    "#                              num_eval_envs=64,\n",
    "#                              num_evals=10 + 1,\n",
    "#                              use_float64=True,\n",
    "#                              normalize_observations=True,\n",
    "#                              network_factory=make_networks_factory)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data = []\n",
    "# y_data = []\n",
    "# ydataerr = []\n",
    "# y_pose_error = []  # to store pose error\n",
    "# times = [datetime.now()]\n",
    "# max_y_rewards, min_y_rewards = 0, -5\n",
    "# def progress(num_steps, metrics):\n",
    "  \n",
    "#   #print(num_steps)\n",
    "#   times.append(datetime.now())\n",
    "#   x_data.append(num_steps)\n",
    "#   y_data.append(metrics['eval/episode_reward'])\n",
    "#   ydataerr.append(metrics['eval/episode_reward_std'])\n",
    "#   #y_pose_error.append(metrics['eval/episode_pose_error'])  # capture pose error\n",
    "  \n",
    "#   plt.figure(figsize=(10, 5))\n",
    "#   plt.subplot(1, 2, 1) \n",
    "#   plt.xlim([0, num_steps* 1.25])\n",
    "#   plt.ylim([max_y_rewards, min_y_rewards])\n",
    "\n",
    "#   plt.xlabel('# environment steps')\n",
    "#   plt.ylabel('reward per episode')\n",
    "#   plt.title(f'Latest Reward: {y_data[-1]:.3f}')\n",
    "#   plt.plot(x_data, y_data, '-o')\n",
    "  \n",
    "#   # plt.subplot(1, 2, 2)\n",
    "#   # plt.xlim([0, num_steps* 1.25])\n",
    "#   # plt.ylim([min(y_pose_error) * 0.9, max(y_pose_error) * 1.1])\n",
    "#   # plt.xlabel('# Environment Steps')\n",
    "#   # plt.ylabel('Pose Error per Episode')\n",
    "#   # plt.title(f'Latest Pose Error: {y_pose_error[-1]:.3f}')\n",
    "#   # plt.plot(x_data, y_pose_error, '-o')\n",
    "  \n",
    "\n",
    "#   plt.tight_layout()\n",
    "#   plt.show()\n",
    "  \n",
    "\n",
    "# make_inference_fn, params, _= train_fn(environment=env_apg,\n",
    "#                                        progress_fn=progress,\n",
    "#                                        eval_env=env_apg)\n",
    "\n",
    "# print(f'time to jit: {times[1] - times[0]}')\n",
    "# print(f'time to train: {times[-1] - times[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function make_ppo_networks at 0x7ff958936de0>, policy_hidden_layer_sizes=(512, 256), value_hidden_layer_sizes=(512, 256))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "make_networks_factory = functools.partial(\n",
    "    ppo_networks.make_ppo_networks,\n",
    "        policy_hidden_layer_sizes=(512,256),\n",
    "        value_hidden_layer_sizes=(512,256))\n",
    "make_networks_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = functools.partial(\n",
    "    ppo.train, num_timesteps=episode_len-1, num_evals=10, reward_scaling=0.1,\n",
    "    episode_length=1000, normalize_observations=True, action_repeat=1,\n",
    "    unroll_length=15, num_minibatches=24, num_updates_per_batch=8,\n",
    "    discounting=0.97, learning_rate=3e-4, entropy_cost=1e-3, num_envs=256,\n",
    "    batch_size=256, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19747/1806796254.py:18: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "  plt.xlim([0, num_steps* 1.25])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Scanned function carry input and carry output must have equal types (e.g. shapes and dtypes of arrays), but they differ:\n  * the input carry component state.metrics['step_index'] has type int64[] but the corresponding output carry component has type int32[], so the dtypes do not match\n\nRevise the scanned function so that all output types (e.g. shapes and dtypes) match the corresponding input types.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m   plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     36\u001b[0m   plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 39\u001b[0m make_inference_fn, params, _\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mprogress_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime to jit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtimes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime to train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtimes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/training/agents/ppo/train.py:423\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(environment, num_timesteps, episode_length, action_repeat, num_envs, max_devices_per_host, num_eval_envs, learning_rate, entropy_cost, discounting, seed, unroll_length, batch_size, num_minibatches, num_updates_per_batch, num_evals, num_resets_per_eval, normalize_observations, reward_scaling, clipping_epsilon, gae_lambda, deterministic_eval, network_factory, progress_fn, normalize_advantage, eval_env, policy_params_fn, randomization_fn)\u001b[0m\n\u001b[1;32m    420\u001b[0m epoch_key, local_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(local_key)\n\u001b[1;32m    421\u001b[0m epoch_keys \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(epoch_key, local_devices_to_use)\n\u001b[1;32m    422\u001b[0m (training_state, env_state, training_metrics) \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 423\u001b[0m     \u001b[43mtraining_epoch_with_timing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m )\n\u001b[1;32m    425\u001b[0m current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(_unpmap(training_state\u001b[38;5;241m.\u001b[39menv_steps))\n\u001b[1;32m    427\u001b[0m key_envs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x, s: jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(x[\u001b[38;5;241m0\u001b[39m], s),\n\u001b[1;32m    429\u001b[0m     in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))(key_envs, key_envs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/training/agents/ppo/train.py:350\u001b[0m, in \u001b[0;36mtrain.<locals>.training_epoch_with_timing\u001b[0;34m(training_state, env_state, key)\u001b[0m\n\u001b[1;32m    348\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    349\u001b[0m training_state, env_state \u001b[38;5;241m=\u001b[39m _strip_weak_type((training_state, env_state))\n\u001b[0;32m--> 350\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m training_state, env_state, metrics \u001b[38;5;241m=\u001b[39m _strip_weak_type(result)\n\u001b[1;32m    353\u001b[0m metrics \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(jnp\u001b[38;5;241m.\u001b[39mmean, metrics)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/training/agents/ppo/train.py:335\u001b[0m, in \u001b[0;36mtrain.<locals>.training_epoch\u001b[0;34m(training_state, state, key)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_epoch\u001b[39m(training_state: TrainingState, state: envs\u001b[38;5;241m.\u001b[39mState,\n\u001b[1;32m    334\u001b[0m                    key: PRNGKey) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[TrainingState, envs\u001b[38;5;241m.\u001b[39mState, Metrics]:\n\u001b[0;32m--> 335\u001b[0m   (training_state, state, _), loss_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_training_steps_per_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m   loss_metrics \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(jnp\u001b[38;5;241m.\u001b[39mmean, loss_metrics)\n\u001b[1;32m    339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m training_state, state, loss_metrics\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/training/agents/ppo/train.py:305\u001b[0m, in \u001b[0;36mtrain.<locals>.training_step\u001b[0;34m(carry, unused_t)\u001b[0m\n\u001b[1;32m    296\u001b[0m   next_state, data \u001b[38;5;241m=\u001b[39m acting\u001b[38;5;241m.\u001b[39mgenerate_unroll(\n\u001b[1;32m    297\u001b[0m       env,\n\u001b[1;32m    298\u001b[0m       current_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m       unroll_length,\n\u001b[1;32m    302\u001b[0m       extra_fields\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m'\u001b[39m,))\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (next_state, next_key), data\n\u001b[0;32m--> 305\u001b[0m (state, _), data \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_generate_unroll\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_minibatches\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Have leading dimensions (batch_size * num_minibatches, unroll_length)\u001b[39;00m\n\u001b[1;32m    309\u001b[0m data \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: jnp\u001b[38;5;241m.\u001b[39mswapaxes(x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), data)\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/training/agents/ppo/train.py:296\u001b[0m, in \u001b[0;36mtrain.<locals>.training_step.<locals>.f\u001b[0;34m(carry, unused_t)\u001b[0m\n\u001b[1;32m    294\u001b[0m current_state, current_key \u001b[38;5;241m=\u001b[39m carry\n\u001b[1;32m    295\u001b[0m current_key, next_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(current_key)\n\u001b[0;32m--> 296\u001b[0m next_state, data \u001b[38;5;241m=\u001b[39m \u001b[43macting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_unroll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43munroll_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtruncation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (next_state, next_key), data\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/training/acting.py:75\u001b[0m, in \u001b[0;36mgenerate_unroll\u001b[0;34m(env, env_state, policy, key, unroll_length, extra_fields)\u001b[0m\n\u001b[1;32m     71\u001b[0m   nstate, transition \u001b[38;5;241m=\u001b[39m actor_step(\n\u001b[1;32m     72\u001b[0m       env, state, policy, current_key, extra_fields\u001b[38;5;241m=\u001b[39mextra_fields)\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (nstate, next_key), transition\n\u001b[0;32m---> 75\u001b[0m (final_state, _), data \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munroll_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_state, data\n",
      "    \u001b[0;31m[... skipping hidden 20 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/training/acting.py:71\u001b[0m, in \u001b[0;36mgenerate_unroll.<locals>.f\u001b[0;34m(carry, unused_t)\u001b[0m\n\u001b[1;32m     69\u001b[0m state, current_key \u001b[38;5;241m=\u001b[39m carry\n\u001b[1;32m     70\u001b[0m current_key, next_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(current_key)\n\u001b[0;32m---> 71\u001b[0m nstate, transition \u001b[38;5;241m=\u001b[39m \u001b[43mactor_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (nstate, next_key), transition\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/training/acting.py:43\u001b[0m, in \u001b[0;36mactor_step\u001b[0;34m(env, env_state, policy, key, extra_fields)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Collect data.\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m actions, policy_extras \u001b[38;5;241m=\u001b[39m policy(env_state\u001b[38;5;241m.\u001b[39mobs, key)\n\u001b[0;32m---> 43\u001b[0m nstate \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m state_extras \u001b[38;5;241m=\u001b[39m {x: nstate\u001b[38;5;241m.\u001b[39minfo[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m extra_fields}\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nstate, Transition(  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types  # jax-ndarray\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     observation\u001b[38;5;241m=\u001b[39menv_state\u001b[38;5;241m.\u001b[39mobs,\n\u001b[1;32m     47\u001b[0m     action\u001b[38;5;241m=\u001b[39mactions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_extras\u001b[39m\u001b[38;5;124m'\u001b[39m: state_extras\n\u001b[1;32m     54\u001b[0m     })\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/envs/wrappers/training.py:122\u001b[0m, in \u001b[0;36mAutoResetWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    120\u001b[0m   state\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mupdate(steps\u001b[38;5;241m=\u001b[39msteps)\n\u001b[1;32m    121\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreplace(done\u001b[38;5;241m=\u001b[39mjp\u001b[38;5;241m.\u001b[39mzeros_like(state\u001b[38;5;241m.\u001b[39mdone))\n\u001b[0;32m--> 122\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwhere_done\u001b[39m(x, y):\n\u001b[1;32m    125\u001b[0m   done \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mdone\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/envs/wrappers/training.py:71\u001b[0m, in \u001b[0;36mVmapWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: State, action: jax\u001b[38;5;241m.\u001b[39mArray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m State:\n\u001b[0;32m---> 71\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/brax/envs/wrappers/training.py:93\u001b[0m, in \u001b[0;36mEpisodeWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     90\u001b[0m   nstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(state, action)\n\u001b[1;32m     91\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nstate, nstate\u001b[38;5;241m.\u001b[39mreward\n\u001b[0;32m---> 93\u001b[0m state, rewards \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_repeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreplace(reward\u001b[38;5;241m=\u001b[39mjp\u001b[38;5;241m.\u001b[39msum(rewards, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     95\u001b[0m steps \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_repeat\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/newBrax/lib/python3.11/site-packages/jax/_src/lax/control_flow/loops.py:352\u001b[0m, in \u001b[0;36m_check_scan_carry_type\u001b[0;34m(body_fun, in_carry, out_carry_tree, out_avals)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_map(core\u001b[38;5;241m.\u001b[39mtypematch, in_avals, out_avals)):\n\u001b[1;32m    346\u001b[0m   differences \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    347\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  * \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomponent(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_aval\u001b[38;5;241m.\u001b[39mstr_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    348\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but the corresponding output carry component has type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    349\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_aval\u001b[38;5;241m.\u001b[39mstr_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_aval_mismatch_extra(in_aval,\u001b[38;5;250m \u001b[39mout_aval)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    350\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m path, in_aval, out_aval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(paths, in_avals, out_avals)\n\u001b[1;32m    351\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mtypematch(in_aval, out_aval))\n\u001b[0;32m--> 352\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    353\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScanned function carry input and carry output must have equal types \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(e.g. shapes and dtypes of arrays), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut they differ:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdifferences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevise the scanned function so that all output types (e.g. shapes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand dtypes) match the corresponding input types.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m   )\n",
      "\u001b[0;31mTypeError\u001b[0m: Scanned function carry input and carry output must have equal types (e.g. shapes and dtypes of arrays), but they differ:\n  * the input carry component state.metrics['step_index'] has type int64[] but the corresponding output carry component has type int32[], so the dtypes do not match\n\nRevise the scanned function so that all output types (e.g. shapes and dtypes) match the corresponding input types."
     ]
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "ydataerr = []\n",
    "y_pose_error = []  # to store pose error\n",
    "times = [datetime.now()]\n",
    "max_y_rewards, min_y_rewards = 0, -5\n",
    "def progress(num_steps, metrics):\n",
    "  \n",
    "  #print(num_steps)\n",
    "  times.append(datetime.now())\n",
    "  x_data.append(num_steps)\n",
    "  y_data.append(metrics['eval/episode_reward'])\n",
    "  ydataerr.append(metrics['eval/episode_reward_std'])\n",
    "  #y_pose_error.append(metrics['eval/episode_pose_error'])  # capture pose error\n",
    "  \n",
    "  plt.figure(figsize=(10, 5))\n",
    "  plt.subplot(1, 2, 1) \n",
    "  plt.xlim([0, num_steps* 1.25])\n",
    "  plt.ylim([max_y_rewards, min_y_rewards])\n",
    "\n",
    "  plt.xlabel('# environment steps')\n",
    "  plt.ylabel('reward per episode')\n",
    "  plt.title(f'Latest Reward: {y_data[-1]:.3f}')\n",
    "  plt.plot(x_data, y_data, '-o')\n",
    "  \n",
    "  # plt.subplot(1, 2, 2)\n",
    "  # plt.xlim([0, num_steps* 1.25])\n",
    "  # plt.ylim([min(y_pose_error) * 0.9, max(y_pose_error) * 1.1])\n",
    "  # plt.xlabel('# Environment Steps')\n",
    "  # plt.ylabel('Pose Error per Episode')\n",
    "  # plt.title(f'Latest Pose Error: {y_pose_error[-1]:.3f}')\n",
    "  # plt.plot(x_data, y_pose_error, '-o')\n",
    "  \n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "make_inference_fn, params, _= train_fn(environment=env,\n",
    "                                       progress_fn=progress,\n",
    "                                       eval_env=env_eval)\n",
    "\n",
    "print(f'time to jit: {times[1] - times[0]}')\n",
    "print(f'time to train: {times[-1] - times[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
